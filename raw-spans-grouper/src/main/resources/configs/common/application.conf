service.name = raw-spans-grouper
service.admin.port = 8099

main.class = org.hypertrace.core.rawspansgrouper.RawSpansGrouper

span.type = rawSpan

flink.job {
  metrics {
    metrics.reporters = "prometheus"
    metrics.reporter.prometheus.class = "org.hypertrace.core.serviceframework.metrics.flink.PrometheusReporter"
  }
}

flink.source {
  type = kafka
  topic = raw-spans-from-jaeger-spans
  schema.registry {
    schema.registry.url = "http://localhost:8081"
    schema.registry.url = ${?SCHEMA_REGISTRY_URL}
    specific.avro.reader = true
  }
  kafka {
    bootstrap.servers = "localhost:9092"
    bootstrap.servers = ${?KAFKA_BOOTSTRAP_SERVERS}
    group.id = "raw-spans-to-structured-traces-grouping-job"
    auto.offset.reset = "latest"
    enable.auto.commit = true
    auto.commit.interval.ms = 5000
  }
}

flink.sink {
  type = kafka
  topic = structured-traces-from-raw-spans
  log.failures.only = true
  schema.registry {
    schema.registry.url = "http://localhost:8081"
    schema.registry.url = ${?SCHEMA_REGISTRY_URL}
    value.subject.name.strategy = "io.confluent.kafka.serializers.subject.TopicRecordNameStrategy"
  }
  kafka {
    bootstrap.servers = "localhost:9092"
    bootstrap.servers = ${?KAFKA_BOOTSTRAP_SERVERS}
  }
}

span.groupby.session.window.interval = 30
span.groupby.session.window.interval = ${?SPAN_GROUPBY_SESSION_WINDOW_INTERVAL}

logger {
  names = ["file"]
  file {
    dir = "/var/logs/raw-spans-grouper"
  }
}

metrics.reporter {
  prefix = org.hypertrace.core.rawspansgrouper.RawSpansGrouper
  names = ["prometheus"]
  console.reportInterval = 30
}

dataflow.metriccollection.sampling.percent = 10.0
