service.name = raw-spans-grouper
service.admin.port = 8099

main.class = org.hypertrace.core.rawspansgrouper.RawSpansGrouper

span.type = rawSpan
input.topic = "raw-spans-from-jaeger-spans"
output.topic = "structured-traces-from-raw-spans"
precreate.topics = false
precreate.topics = ${?PRE_CREATE_TOPICS}

kafka.streams.config = {
  application.id = raw-spans-to-structured-traces-grouping-job
  state.dir = "/var/data/"
  metrics.recording.level = INFO
  num.stream.threads = 2
  producer.compression.type = gzip
  producer.max.request.size = 10485760
  topology.optimization = all

  bootstrap.servers = "localhost:9092"
  bootstrap.servers = ${?KAFKA_BOOTSTRAP_SERVERS}
  auto.offset.reset = "latest"
  auto.commit.interval.ms = 5000

  schema.registry.url = "http://localhost:8081"
  schema.registry.url = ${?SCHEMA_REGISTRY_URL}
  specific.avro.reader = true

  rocksdb.config.setter = org.hypertrace.core.kafkastreams.framework.rocksdb.RocksDBStateStoreConfigSetter
  rocksdb.block.cache.size = 33554432
  rocksdb.write.buffer.size = 8388608
  rocksdb.max.write.buffers = 2
  rocksdb.cache.index.and.filter.blocks = true
}

span.groupby.session.window.interval = 30
span.groupby.session.window.interval = ${?SPAN_GROUPBY_SESSION_WINDOW_INTERVAL}

logger {
  names = ["file"]
  file {
    dir = "/var/logs/raw-spans-grouper"
  }
}

metrics.reporter {
  prefix = org.hypertrace.core.rawspansgrouper.RawSpansGrouper
  names = ["prometheus"]
  console.reportInterval = 30
}

dataflow.metriccollection.sampling.percent = 10.0
