service.name = raw-span-to-structured-trace-grouper
service.admin.port = 8099

main.class = org.hypertrace.core.rawspansgrouper.RawSpansGrouper

span.type = rawSpan

flink.job {
  parallelism = 4
  metrics {
    metrics.reporters = "prometheus"
    metrics.reporter.prometheus.class = "org.hypertrace.core.serviceframework.metrics.flink.PrometheusReporter"
  }
}

flink.source {
  type = kafka
  topic = raw-spans-from-jaeger-spans
  schema.registry {
    schema.registry.url = "mock://localhost:8081"
    specific.avro.reader = true
  }
  kafka {
    bootstrap.servers = "localhost:9092"
    group.id = "raw-spans-to-structured-traces-grouping-job"
    auto.offset.reset = "latest"
    enable.auto.commit = true
    auto.commit.interval.ms = 5000
  }
}

flink.sink {
  type = kafka
  topic = structured-traces-from-raw-spans
  log.failures.only = true
  schema.registry {
    schema.registry.url = "mock://localhost:8081"
  }
  kafka {
    bootstrap.servers = "localhost:9092"
  }
}

span.groupby.session.window.interval = 30

logger {
  names = ["file"]
  file {
    dir = "/var/logs/raw-spans-grouper"
  }
}

metrics.reporter {
  prefix = org.hypertrace.core.rawspansgrouper.RawSpansGrouper
  names = ["prometheus"]
  console.reportInterval = 30
}

dataflow.metriccollection.sampling.percent = 10